{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "168e1e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jongsu/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from NeuralNetwork import NN\n",
    "from control import BASE, policy\n",
    "from utils import converter\n",
    "from control import policy\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acff5b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d79a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to establish dbus connection"
     ]
    }
   ],
   "source": [
    "n_p_o = env.reset()\n",
    "t = 0\n",
    "while t < 1000:\n",
    "    n_a = np.random.randint(2)\n",
    "    n_o, n_r, n_d, info = env.step(n_a)\n",
    "    env.render()\n",
    "    if n_d == 1:\n",
    "        env.reset()\n",
    "    t = t + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20478fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.,  8., 18.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Multiplication tensors element by element\n",
    "a  = torch.tensor([1.,2., 3.])\n",
    "b = torch.tensor([4., 4., 6.])\n",
    "a.mul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b770c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.,  8., 18.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01913c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4., 6.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(b.unsqueeze(-1),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b49ccea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_ = b.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c66d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ = a.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa82baa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  8., 12.],\n",
       "        [ 4.,  8., 12.],\n",
       "        [ 6., 12., 18.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_*a_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a26546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Converter:\n",
    "    def __init__(self, envname):\n",
    "        self.envname = envname\n",
    "\n",
    "    def index2act(self, _input, batch):\n",
    "        if self.envname == \"hope\":\n",
    "            if batch == 1:\n",
    "                first_action = (_input % 5 / 2) - 1\n",
    "                sec_action = ((_input % 25 - _input % 5) / 10) - 1\n",
    "                third_action = ((_input - _input % 25) / 50) - 1\n",
    "                out = np.array([first_action, sec_action, third_action])\n",
    "            else:\n",
    "                i = 0\n",
    "                out = np.zeros((batch, 3))\n",
    "                while i < batch:\n",
    "                    first_action = (_input[i] % 5 / 2) - 1\n",
    "                    sec_action = ((_input[i] % 25 - _input[i] % 5) / 10) - 1\n",
    "                    third_action = ((_input[i] - _input[i] % 25) / 50) - 1\n",
    "                    out[i] = np.array([first_action, sec_action, third_action])\n",
    "                    i = i + 1\n",
    "            return out\n",
    "        elif self.envname == \"cart\":\n",
    "            return _input\n",
    "        else:\n",
    "            print(\"converter error\")\n",
    "\n",
    "    def act2index(self, _input, batch):\n",
    "        if self.envname == \"hope\":\n",
    "            if batch == 1:\n",
    "                _input = _input + 1\n",
    "                _input = _input * 2\n",
    "                out = _input[2] * 25 + _input[1] * 5 + _input[0]\n",
    "            else:\n",
    "                i = 0\n",
    "                out = np.zeros(batch)\n",
    "                while i < batch:\n",
    "                    _input[i] = _input[i] + 1\n",
    "                    _input[i] = _input[i] * 2\n",
    "                    out[i] = _input[i][2] * 25 + _input[i][1] * 5 + _input[i][0]\n",
    "                    i = i + 1\n",
    "            return out\n",
    "        elif self.envname == \"cart\":\n",
    "            return _input\n",
    "        else:\n",
    "            print(\"converter error\")\n",
    "\n",
    "    def rand_act(self):\n",
    "        if self.envname == \"hope\":\n",
    "            return (np.random.randint(5, size=3) - 2)/2\n",
    "        elif self.envname == \"cart\":\n",
    "            a = np.random.randint(2)\n",
    "            return np.int64(a)\n",
    "        else:\n",
    "            print(\"converter error\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4674734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "out = np.zeros((10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4d9f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.zeros((10,3),device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead41d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72750c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[3] = torch.tensor([2, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34d52a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [2., 3., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4696007f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(3, 4, (3,)) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04f0acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = torch.randint(2, size = (1,))[0]\n",
    "n_a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21041d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00523264,  0.23816238,  0.03059083, -0.33227867], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v1')\n",
    "env.step(n_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "459a975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_a = np.random.randint(2, size=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "877c43bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "649e8cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -1., -1.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.random.randint(5, size=(3,)) - 2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7fd0cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('logs/')\n",
    "x = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
    "y = -5 * x + 0.1 * torch.randn(x.size())\n",
    "\n",
    "model = torch.nn.Linear(1, 1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "def train_model(iter):\n",
    "    for epoch in range(iter):\n",
    "        y1 = model(x)\n",
    "        loss = criterion(y1, y)\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"aa\")\n",
    "\n",
    "train_model(10)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c071a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f17382fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, input_element):\n",
    "        output = self.linear_relu_stack(input_element)\n",
    "        return output\n",
    "\n",
    "base = SimpleNN(10, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd80e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros((3,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03880909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b37d15ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0924c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(base(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b03d7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(base(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "089d7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "475dbdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "963a62c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b67de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#kl_loss = nn.KLDivLoss(reduction=\"batchmean\", log_target=True)\n",
    "#log_target = F.log_softmax(torch.rand(3, 5))\n",
    "#output = kl_loss(input_, log_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46de6353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3845/1812325958.py:3: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input_ = F.log_softmax(torch.randn(3, 5, requires_grad=True))\n",
      "/tmp/ipykernel_3845/1812325958.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  target = F.softmax(torch.rand(3, 5))\n"
     ]
    }
   ],
   "source": [
    "kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "# input should be a distribution in the log space\n",
    "input_ = F.log_softmax(torch.randn(3, 5, requires_grad=True))\n",
    "# Sample a batch of distributions. Usually this would come from the dataset\n",
    "target = F.softmax(torch.rand(3, 5))\n",
    "output = kl_loss(input_, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f6d3b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8688, -1.2160, -2.3048, -0.7909, -2.3684],\n",
       "        [-3.1746, -4.4358, -0.2845, -4.6341, -1.6916],\n",
       "        [-1.0830, -3.3001, -1.5137, -1.1018, -2.6286]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "017f9673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2261, 0.1140, 0.2669, 0.2333, 0.1596],\n",
       "        [0.1896, 0.2127, 0.2101, 0.2110, 0.1767],\n",
       "        [0.1296, 0.3074, 0.1633, 0.1643, 0.2354]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd20dd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7708, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cde01b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0793, grad_fn=<DivBackward0>)\n",
      "tensor(0.2550, grad_fn=<DivBackward0>)\n",
      "tensor(0.1283, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(kl_loss(input_[0], target[0]))\n",
    "print(kl_loss(input_[1], target[1]))\n",
    "print(kl_loss(input_[2], target[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6430dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94c519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jongsu/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, input_element):\n",
    "        output = self.linear_relu_stack(input_element)\n",
    "        return output\n",
    "\n",
    "mynn = SimpleNN(2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8607498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.tensor([1.0, 2.0])\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd17fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7106])\n",
      "tensor([0.5686])\n",
      "tensor([0.4496])\n",
      "tensor([0.3447])\n",
      "tensor([0.2490])\n",
      "tensor([0.1592])\n",
      "tensor([0.0735])\n",
      "tensor([-0.0096])\n",
      "tensor([-0.0912])\n",
      "tensor([-0.1723])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 10:\n",
    "    i = i + 1\n",
    "    with torch.no_grad():\n",
    "        new = mynn(k)\n",
    "    neww = new.clone().detach()\n",
    "    print(neww)\n",
    "    loss = criterion(mynn(k),torch.tensor([1.35])) + 10*(mynn(k)-neww)\n",
    "    opt = torch.optim.SGD(mynn.parameters(), lr=0.01)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2452f6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13261955589475294"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.98**100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748fcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
